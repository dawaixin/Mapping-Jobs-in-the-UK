<div class="container">
    <!-- About Section Heading-->
    <h2 class="page-section-heading text-center text-uppercase text-white">Models</h2>
    <!-- Icon Divider-->
    <div class="divider-custom divider-light">
        <div class="divider-custom-line"></div>
    </div>
    <!-- About Section Content-->
    <div class="row">
        <div class="col-sm ml-auto" style="text-align: justify">
            <p class="lead">
                Two different models were experimented with over the course of the project. These are Latent Dirichlet Allocation
                (LDA) and Doc2Vec. The first is an extremely popular model introduced in 2003 by Blei et al. [1]. This model aims to
                find a probabilistic model that assigns high probabilities to texts within the corpus of documents provided for training
                but also for other similar documents. The variant used for the project is the Variational Bayes LDA algorithm developed
                by Hoffman et al. [2] and implemented in the Scikit Python library [3]. The second model used was doc2vec. This model is more
                recent than LDA and was
                introduced by Mikolov et al. [4, 5] represents the entire document being  given to the model as a single (large) vector.
                The implemented version was the one provided by the Gensim Python library [6]. Further details can be found in section
                3 of the full report (see About section below).
            </p>
        </div>
    </div>
</div>